split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.5264 (0.5264)	0.0957 (0.0957)	0.695 (0.695)	49.22 (49.22)
[100/469]	0.0174 (0.0123)	0.0153 (0.0060)	0.144 (0.199)	92.97 (91.94)
[200/469]	0.0021 (0.0098)	0.0001 (0.0056)	0.108 (0.150)	96.09 (94.12)
[300/469]	0.0029 (0.0089)	0.0009 (0.0055)	0.066 (0.126)	96.88 (95.09)
[400/469]	0.0161 (0.0086)	0.0141 (0.0055)	0.042 (0.114)	99.22 (95.68)
[468/469]	0.0026 (0.0084)	0.0005 (0.0054)	0.031 (0.107)	98.96 (95.95)
 * Train Acc 95.953
 * Val Acc 98.020, Total time 0.72
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1119 (0.1119)	0.1063 (0.1063)	0.095 (0.095)	96.88 (96.88)
[100/469]	0.0019 (0.0084)	0.0002 (0.0064)	0.058 (0.049)	97.66 (98.28)
[200/469]	0.0019 (0.0079)	0.0001 (0.0060)	0.054 (0.050)	99.22 (98.27)
[300/469]	0.0175 (0.0078)	0.0157 (0.0059)	0.011 (0.050)	100.00 (98.25)
[400/469]	0.0019 (0.0077)	0.0001 (0.0058)	0.113 (0.050)	96.09 (98.25)
[468/469]	0.0122 (0.0076)	0.0105 (0.0058)	0.105 (0.050)	96.88 (98.25)
 * Train Acc 98.248
 * Val Acc 98.300, Total time 0.71
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1170 (0.1170)	0.1113 (0.1113)	0.036 (0.036)	99.22 (99.22)
[100/469]	0.0019 (0.0084)	0.0001 (0.0063)	0.016 (0.037)	99.22 (98.65)
[200/469]	0.0187 (0.0080)	0.0166 (0.0060)	0.030 (0.038)	99.22 (98.66)
[300/469]	0.0020 (0.0078)	0.0001 (0.0058)	0.004 (0.036)	100.00 (98.70)
[400/469]	0.0019 (0.0077)	0.0001 (0.0057)	0.015 (0.037)	100.00 (98.71)
[468/469]	0.0019 (0.0076)	0.0001 (0.0056)	0.014 (0.037)	98.96 (98.71)
 * Train Acc 98.707
 * Val Acc 98.350, Total time 0.71
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1146 (0.1146)	0.1090 (0.1090)	0.018 (0.018)	99.22 (99.22)
[100/469]	0.0022 (0.0086)	0.0001 (0.0066)	0.029 (0.028)	98.44 (99.03)
[200/469]	0.0020 (0.0081)	0.0001 (0.0061)	0.028 (0.027)	98.44 (99.06)
[300/469]	0.0188 (0.0079)	0.0167 (0.0060)	0.016 (0.029)	99.22 (99.02)
[400/469]	0.0028 (0.0078)	0.0008 (0.0058)	0.001 (0.029)	100.00 (98.99)
[468/469]	0.0100 (0.0077)	0.0079 (0.0058)	0.021 (0.030)	98.96 (98.97)
 * Train Acc 98.967
 * Val Acc 98.780, Total time 0.72
 * Val Acc 98.780, Total time 0.72
OrderedDict([('All', {'All': 98.78})])
Task All average acc: 98.78
===Summary of experiment repeats: 1 / 5 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.78  0.    0.    0.    0.  ]
mean: 19.756 std: 39.51200000000001
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1225 (0.1225)	0.1137 (0.1137)	0.690 (0.690)	52.34 (52.34)
[100/469]	0.0030 (0.0086)	0.0012 (0.0065)	0.168 (0.202)	94.53 (91.92)
[200/469]	0.0025 (0.0080)	0.0001 (0.0060)	0.101 (0.149)	96.88 (94.24)
[300/469]	0.0171 (0.0079)	0.0151 (0.0058)	0.062 (0.127)	96.88 (95.15)
[400/469]	0.0030 (0.0078)	0.0008 (0.0057)	0.055 (0.112)	97.66 (95.82)
[468/469]	0.0119 (0.0077)	0.0099 (0.0057)	0.067 (0.105)	96.88 (96.09)
 * Train Acc 96.095
 * Val Acc 97.720, Total time 0.73
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1151 (0.1151)	0.1094 (0.1094)	0.025 (0.025)	99.22 (99.22)
[100/469]	0.0018 (0.0086)	0.0001 (0.0066)	0.053 (0.054)	97.66 (98.14)
[200/469]	0.0186 (0.0082)	0.0169 (0.0063)	0.059 (0.054)	98.44 (98.15)
[300/469]	0.0021 (0.0080)	0.0004 (0.0061)	0.028 (0.052)	99.22 (98.19)
[400/469]	0.0018 (0.0078)	0.0001 (0.0060)	0.049 (0.051)	97.66 (98.21)
[468/469]	0.0017 (0.0077)	0.0001 (0.0059)	0.034 (0.050)	97.92 (98.24)
 * Train Acc 98.242
 * Val Acc 98.510, Total time 0.70
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1266 (0.1266)	0.1206 (0.1206)	0.035 (0.035)	99.22 (99.22)
[100/469]	0.0022 (0.0089)	0.0001 (0.0069)	0.014 (0.037)	99.22 (98.79)
[200/469]	0.0179 (0.0082)	0.0158 (0.0062)	0.073 (0.038)	96.88 (98.74)
[300/469]	0.0019 (0.0079)	0.0001 (0.0059)	0.008 (0.038)	100.00 (98.71)
[400/469]	0.0019 (0.0077)	0.0001 (0.0057)	0.016 (0.037)	100.00 (98.71)
[468/469]	0.0021 (0.0077)	0.0001 (0.0057)	0.059 (0.038)	97.92 (98.70)
 * Train Acc 98.702
 * Val Acc 98.760, Total time 0.72
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1249 (0.1249)	0.1192 (0.1192)	0.011 (0.011)	100.00 (100.00)
[100/469]	0.0019 (0.0087)	0.0001 (0.0067)	0.052 (0.028)	98.44 (99.09)
[200/469]	0.0166 (0.0081)	0.0146 (0.0060)	0.042 (0.026)	98.44 (99.14)
[300/469]	0.0020 (0.0078)	0.0001 (0.0058)	0.006 (0.028)	100.00 (99.05)
[400/469]	0.0022 (0.0077)	0.0001 (0.0057)	0.019 (0.029)	99.22 (99.02)
[468/469]	0.0017 (0.0078)	0.0001 (0.0057)	0.018 (0.028)	98.96 (99.03)
 * Train Acc 99.028
 * Val Acc 98.750, Total time 0.75
 * Val Acc 98.750, Total time 0.73
OrderedDict([('All', {'All': 98.75})])
Task All average acc: 98.75
===Summary of experiment repeats: 2 / 5 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.78 98.75  0.    0.    0.  ]
mean: 39.506 std: 48.38477181924081
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1158 (0.1158)	0.1100 (0.1100)	0.704 (0.704)	47.66 (47.66)
[100/469]	0.0054 (0.0084)	0.0035 (0.0065)	0.101 (0.204)	96.88 (91.92)
[200/469]	0.0019 (0.0079)	0.0001 (0.0060)	0.060 (0.149)	98.44 (94.22)
[300/469]	0.0116 (0.0078)	0.0097 (0.0058)	0.110 (0.126)	96.88 (95.24)
[400/469]	0.0108 (0.0077)	0.0087 (0.0057)	0.121 (0.113)	96.88 (95.79)
[468/469]	0.0038 (0.0076)	0.0017 (0.0057)	0.073 (0.106)	97.92 (96.05)
 * Train Acc 96.045
 * Val Acc 98.090, Total time 0.71
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1191 (0.1191)	0.1133 (0.1133)	0.076 (0.076)	97.66 (97.66)
[100/469]	0.0035 (0.0085)	0.0015 (0.0064)	0.012 (0.057)	100.00 (97.90)
[200/469]	0.0019 (0.0079)	0.0001 (0.0059)	0.123 (0.055)	96.88 (98.02)
[300/469]	0.0180 (0.0078)	0.0159 (0.0058)	0.054 (0.053)	97.66 (98.13)
[400/469]	0.0029 (0.0077)	0.0009 (0.0057)	0.056 (0.051)	97.66 (98.19)
[468/469]	0.0124 (0.0076)	0.0104 (0.0057)	0.040 (0.050)	98.96 (98.25)
 * Train Acc 98.252
 * Val Acc 97.660, Total time 0.71
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1160 (0.1160)	0.1106 (0.1106)	0.037 (0.037)	97.66 (97.66)
[100/469]	0.0128 (0.0090)	0.0110 (0.0072)	0.039 (0.039)	99.22 (98.69)
[200/469]	0.0166 (0.0082)	0.0148 (0.0064)	0.014 (0.040)	100.00 (98.63)
[300/469]	0.0019 (0.0080)	0.0001 (0.0061)	0.057 (0.039)	96.88 (98.64)
[400/469]	0.0032 (0.0078)	0.0015 (0.0060)	0.036 (0.038)	98.44 (98.68)
[468/469]	0.0021 (0.0078)	0.0001 (0.0059)	0.019 (0.037)	98.96 (98.69)
 * Train Acc 98.687
 * Val Acc 98.670, Total time 0.70
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1153 (0.1153)	0.1097 (0.1097)	0.012 (0.012)	99.22 (99.22)
[100/469]	0.0184 (0.0089)	0.0163 (0.0069)	0.002 (0.025)	100.00 (99.16)
[200/469]	0.0023 (0.0082)	0.0001 (0.0062)	0.009 (0.027)	100.00 (99.11)
[300/469]	0.0021 (0.0079)	0.0001 (0.0059)	0.029 (0.028)	98.44 (99.05)
[400/469]	0.0061 (0.0078)	0.0041 (0.0058)	0.025 (0.028)	99.22 (99.05)
[468/469]	0.0019 (0.0078)	0.0001 (0.0058)	0.028 (0.028)	98.96 (99.03)
 * Train Acc 99.028
 * Val Acc 98.970, Total time 0.71
 * Val Acc 98.970, Total time 0.71
OrderedDict([('All', {'All': 98.97})])
Task All average acc: 98.97
===Summary of experiment repeats: 3 / 5 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.78 98.75 98.97  0.    0.  ]
mean: 59.3 std: 48.41830604223985
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1173 (0.1173)	0.1079 (0.1079)	0.699 (0.699)	46.09 (46.09)
[100/469]	0.0036 (0.0084)	0.0018 (0.0065)	0.145 (0.203)	94.53 (91.51)
[200/469]	0.0019 (0.0079)	0.0001 (0.0060)	0.113 (0.147)	95.31 (94.12)
[300/469]	0.0028 (0.0077)	0.0009 (0.0058)	0.105 (0.124)	97.66 (95.16)
[400/469]	0.0181 (0.0076)	0.0161 (0.0057)	0.062 (0.112)	97.66 (95.74)
[468/469]	0.0019 (0.0076)	0.0001 (0.0057)	0.097 (0.106)	95.83 (95.98)
 * Train Acc 95.978
 * Val Acc 98.150, Total time 0.78
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1218 (0.1218)	0.1159 (0.1159)	0.071 (0.071)	98.44 (98.44)
[100/469]	0.0034 (0.0085)	0.0014 (0.0065)	0.078 (0.049)	98.44 (98.30)
[200/469]	0.0029 (0.0079)	0.0008 (0.0059)	0.044 (0.051)	98.44 (98.19)
[300/469]	0.0168 (0.0078)	0.0149 (0.0058)	0.059 (0.050)	98.44 (98.19)
[400/469]	0.0035 (0.0077)	0.0015 (0.0057)	0.037 (0.049)	98.44 (98.25)
[468/469]	0.0116 (0.0077)	0.0095 (0.0057)	0.020 (0.049)	100.00 (98.25)
 * Train Acc 98.247
 * Val Acc 98.300, Total time 0.75
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1169 (0.1169)	0.1110 (0.1110)	0.071 (0.071)	99.22 (99.22)
[100/469]	0.0022 (0.0087)	0.0001 (0.0067)	0.052 (0.033)	98.44 (98.82)
[200/469]	0.0028 (0.0081)	0.0008 (0.0061)	0.020 (0.036)	99.22 (98.78)
[300/469]	0.0033 (0.0079)	0.0011 (0.0059)	0.011 (0.036)	99.22 (98.77)
[400/469]	0.0020 (0.0078)	0.0002 (0.0058)	0.032 (0.036)	99.22 (98.76)
[468/469]	0.0019 (0.0078)	0.0001 (0.0058)	0.012 (0.036)	100.00 (98.78)
 * Train Acc 98.785
 * Val Acc 98.420, Total time 0.71
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1177 (0.1177)	0.1119 (0.1119)	0.030 (0.030)	97.66 (97.66)
[100/469]	0.0034 (0.0085)	0.0015 (0.0065)	0.022 (0.023)	98.44 (99.18)
[200/469]	0.0027 (0.0080)	0.0010 (0.0061)	0.011 (0.026)	100.00 (99.13)
[300/469]	0.0018 (0.0078)	0.0001 (0.0060)	0.038 (0.028)	97.66 (99.09)
[400/469]	0.0191 (0.0078)	0.0173 (0.0059)	0.003 (0.028)	100.00 (99.07)
[468/469]	0.0017 (0.0077)	0.0001 (0.0059)	0.045 (0.028)	97.92 (99.05)
 * Train Acc 99.052
 * Val Acc 98.660, Total time 0.71
 * Val Acc 98.660, Total time 0.73
OrderedDict([('All', {'All': 98.66})])
Task All average acc: 98.66
===Summary of experiment repeats: 4 / 5 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.78 98.75 98.97 98.66  0.  ]
mean: 79.032 std: 39.51612906143515
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1222 (0.1222)	0.1155 (0.1155)	0.697 (0.697)	49.22 (49.22)
[100/469]	0.0171 (0.0087)	0.0150 (0.0066)	0.061 (0.199)	97.66 (91.82)
[200/469]	0.0025 (0.0080)	0.0001 (0.0060)	0.082 (0.148)	98.44 (94.22)
[300/469]	0.0030 (0.0078)	0.0009 (0.0058)	0.037 (0.126)	98.44 (95.18)
[400/469]	0.0178 (0.0078)	0.0157 (0.0057)	0.035 (0.112)	99.22 (95.74)
[468/469]	0.0018 (0.0077)	0.0001 (0.0057)	0.064 (0.106)	97.92 (96.02)
 * Train Acc 96.020
 * Val Acc 97.720, Total time 0.74
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1149 (0.1149)	0.1090 (0.1090)	0.063 (0.063)	96.88 (96.88)
[100/469]	0.0020 (0.0085)	0.0002 (0.0064)	0.039 (0.052)	97.66 (98.16)
[200/469]	0.0028 (0.0080)	0.0008 (0.0059)	0.038 (0.053)	99.22 (98.13)
[300/469]	0.0181 (0.0078)	0.0160 (0.0058)	0.056 (0.053)	98.44 (98.12)
[400/469]	0.0020 (0.0077)	0.0002 (0.0057)	0.047 (0.051)	96.88 (98.19)
[468/469]	0.0120 (0.0077)	0.0100 (0.0057)	0.030 (0.050)	97.92 (98.21)
 * Train Acc 98.207
 * Val Acc 98.630, Total time 0.76
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1092 (0.1092)	0.1037 (0.1037)	0.014 (0.014)	100.00 (100.00)
[100/469]	0.0136 (0.0085)	0.0106 (0.0064)	0.041 (0.032)	98.44 (98.86)
[200/469]	0.0019 (0.0080)	0.0001 (0.0060)	0.057 (0.036)	99.22 (98.76)
[300/469]	0.0029 (0.0078)	0.0010 (0.0059)	0.045 (0.036)	99.22 (98.79)
[400/469]	0.0151 (0.0077)	0.0133 (0.0058)	0.041 (0.036)	99.22 (98.76)
[468/469]	0.0024 (0.0076)	0.0005 (0.0058)	0.108 (0.036)	95.83 (98.72)
 * Train Acc 98.722
 * Val Acc 98.740, Total time 0.70
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1108 (0.1108)	0.1054 (0.1054)	0.013 (0.013)	99.22 (99.22)
[100/469]	0.0182 (0.0086)	0.0161 (0.0065)	0.005 (0.026)	100.00 (99.03)
[200/469]	0.0021 (0.0081)	0.0001 (0.0061)	0.022 (0.026)	99.22 (99.07)
[300/469]	0.0030 (0.0080)	0.0002 (0.0059)	0.016 (0.028)	100.00 (99.04)
[400/469]	0.0196 (0.0081)	0.0168 (0.0059)	0.016 (0.028)	100.00 (99.02)
[468/469]	0.0021 (0.0082)	0.0001 (0.0058)	0.083 (0.029)	97.92 (99.02)
 * Train Acc 99.023
 * Val Acc 98.750, Total time 0.71
 * Val Acc 98.750, Total time 0.71
OrderedDict([('All', {'All': 98.75})])
Task All average acc: 98.75
===Summary of experiment repeats: 5 / 5 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.78 98.75 98.97 98.66 98.75]
mean: 98.782 std: 0.10225458424931412
reg_coef: 0.0 mean: 98.782 std: 0.10225458424931412
Total Time for the script is 92.92869210243225 seconds
